---
title: Maximum Entropy Inverse Reinforcement Learning
date: 2019-02-10
tags: ["프로젝트", "GAIL하자!"]
categories: 프로젝트
author: 이동민
subtitle: Inverse RL 4번째 논문
---

<center> <img src="../../../../img/irl/maxent_1.png" width="850"> </center>

Author : Brian D. Ziebart, Andrew Maas, J.Andrew Bagnell, Anind K. Dey
Paper Link : http://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf
Proceeding : Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence 2008

---

# 0. Abstract

내용

<br><br>

# 1. Introduction

내용

<br><br>

# 2. Background

내용

<br>
## 2.1 MMP와 APP

내용

<br>
## 2.2 The principle of Maximum Entropy

내용

<br><br>

# 3. Maximum Entropy IRL

내용

<br>
## 3.1 Deterministic Path Distributions

내용

<br>
## 3.2 Non-Deterministic Path Distributions

내용

<br>
## 3.3 Stochastic Policies

내용

<br>
## 3.4 Learning from Demonstrated Behavior

내용

<br>
## 3.5 Efficient State Frequency Calculations

내용

<br><br>

# 4. Driver Route Modeling

내용

<br>
## 4.1 Route Choice as an MDP

내용

<br>
## 4.2 Collecting and Processing GPS Data

내용

<br>
## 4.3 Path Features

내용

<br>
## 4.4 IRL Models

내용

<br>
## 4.5 Comparative Evaluation

내용

<br>
## 4.6 Applications

내용

<br><br>

# 5. Conclusions and Future Work

내용

<br><br>

# 처음으로

## [Let's do Inverse RL Guide](https://reinforcement-learning-kr.github.io/2019/01/22/0_lets-do-irl-guide/)

<br>

# 이전으로

## [MMP 여행하기](https://reinforcement-learning-kr.github.io/2019/02/07/3_mmp/)

<br>

# 다음으로

## [MaxEnt Code]()

## [GAIL 여행하기](https://reinforcement-learning-kr.github.io/2019/02/13/5_gail/)